# -*- coding: utf-8 -*-
"""Assigment6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19NB_de7rnbkrH0-xnfTL8VDAn3rY1dqX
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install keras==2.15.0

!pip install tensorflow==2.15.0

import os
import zipfile

# Define paths
zip_file_path = "/content/drive/MyDrive/ColabNotebooks/Kin6.zip"
extract_to = "/content/drive/MyDrive/ColabNotebooks/kin6"  # Directory to extract the dataset

# Function to extract the zip file with error handling
def extract_dataset(zip_file_path, extract_to):
    """
    Extracts a zip file to the specified directory with error handling.
    """
    try:
        print(f"Extracting dataset from {zip_file_path}...")
        if not os.path.exists(extract_to):
            os.makedirs(extract_to, exist_ok=True)  # Create extraction directory if it doesn't exist
        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
        print(f"Dataset extracted to {extract_to}.")
    except zipfile.BadZipFile:
        print("Error: The file is not a valid ZIP file or is corrupted.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

# Extract the dataset
extract_dataset(zip_file_path, extract_to)

import os
import shutil
from glob import glob

# Define paths
original_train_path = "/content/drive/MyDrive/ColabNotebooks/kin6/train/*"
original_test_path = "/content/drive/MyDrive/ColabNotebooks/kin6/test/*"
mini_train_path = "/content/drive/MyDrive/ColabNotebooks/kin6-mini/train"
mini_test_path = "/content/drive/MyDrive/ColabNotebooks/kin6-mini/test"

# Create mini dataset directories
os.makedirs(mini_train_path, exist_ok=True)
os.makedirs(mini_test_path, exist_ok=True)

# Function to copy files for mini dataset
def create_mini_dataset(original_path, mini_path, num_classes=3, num_videos=10):
    classes = sorted(glob(original_path))
    for class_idx, class_path in enumerate(classes[:num_classes]):
        class_name = os.path.basename(class_path)
        mini_class_path = os.path.join(mini_path, class_name)
        os.makedirs(mini_class_path, exist_ok=True)

        videos = sorted(glob(f"{class_path}/*"))[:num_videos]
        for video in videos:
            shutil.copy(video, mini_class_path)
        print(f"Copied {len(videos)} videos from {class_name} to {mini_class_path}")

# Create mini train and test datasets
print("Creating mini train dataset...")
create_mini_dataset(original_train_path, mini_train_path)

print("Creating mini test dataset...")
create_mini_dataset(original_test_path, mini_test_path)

print("Mini dataset created at /content/drive/MyDrive/ColabNotebooks/kin6-mini.")

def all_from_dir(local_path):
    path = np.sort(np.array(glob(local_path)))
    samples = list()
    labels = list()
    for j in range(len(path)):
        v = np.sort(np.array(glob(path[j]+'/*')))
        random.shuffle(v)
        for i in range(len(v)):
            samples.append(v[i])
            labels.append(j)
    return np.array(samples), np.array(labels)

import numpy as np # Import numpy
import random
train_path = '/content/drive/MyDrive/ColabNotebooks/kin6-mini/train/*'
test_path = '/content/drive/MyDrive/ColabNotebooks/kin6-mini/test/*'

train_samples, train_labels = all_from_dir(train_path)
test_samples, test_labels = all_from_dir(test_path)

print("Train Samples:", train_samples)
print("Train Labels:", train_labels)
print("Test Samples:", test_samples)
print("Test Labels:", test_labels)

def prepare_dataset(data, batch_size, frame_count, resolution, n_class, shuffle=True):
    num_samples = len(data)
    if shuffle:
        random.shuffle(data)
    for offset in range(0, num_samples, batch_size):
        video_batch = np.array(data[offset:offset+batch_size]) [:,0]
        label_batch = np.array(data[offset:offset+batch_size]) [:,1]
        X_train = []
        y_train = []
        for (sample, label) in zip(video_batch, label_batch):
            label = to_categorical(label, n_class)
            video_clip = get_clip(sample, frame_count, resolution)
            X_train.append(video_clip)
            y_train.append(label)
        X_train = np.float32(np.array(X_train))
        y_train = np.array(y_train)
        yield X_train, y_train

!pip install decord

!ls "/content/drive/MyDrive/ColabNotebooks/kin6-mini/train/crawling_baby/"

def format_frames(frame, resolution):
    """
    Converts a single video frame to a TensorFlow-compatible format.

    Parameters:
        frame (numpy array): The video frame.
        resolution (int): Target resolution for resizing the frame (e.g., 224 for 224x224).

    Returns:
        numpy array: The processed frame.
    """
    output_size = [resolution, resolution]
    frame = tf.image.convert_image_dtype(frame, tf.uint8)  # Convert to uint8
    frame = tf.image.resize(frame, size=output_size)  # Resize to target resolution
    frame = tf.image.per_image_standardization(frame)  # Normalize
    return frame

import numpy as np
import tensorflow as tf
from decord import VideoReader, cpu

# Function to get a fixed number of frames from a video
def get_clip(file_path, frame_count, resolution):
    """
    Extracts a fixed number of frames from a video file and resizes them.
    If the video has fewer frames than `frame_count`, repeats frames to match the required count.

    Parameters:
        file_path (str): Path to the video file.
        frame_count (int): Number of frames to extract.
        resolution (int): Target resolution for resizing frames (e.g., 224 for 224x224).

    Returns:
        np.array: Array of processed video frames of shape (frame_count, resolution, resolution, 3).
    """
    try:
        # Read the video file
        vr = VideoReader(file_path, ctx=cpu(0))  # Use CPU for reading video
        total_frames = len(vr)  # Total frames in the video

        # Generate frame indices using linspace
        if total_frames < frame_count:
            frame_indices = np.linspace(0, total_frames - 1, frame_count, endpoint=True)
        else:
            frame_indices = np.linspace(0, total_frames - 1, frame_count, endpoint=True)

        frame_indices = np.int64(frame_indices)  # Convert to integer frame indices

        # Read frames and process
        frames = [vr[idx].asnumpy() for idx in frame_indices]  # Read and convert frames to numpy
        processed_frames = [format_frames(frame, resolution) for frame in frames]  # Resize and normalize

        # Convert to NumPy array and return
        return np.array(processed_frames)

    except Exception as e:
        print(f"Error processing video {file_path}: {e}")
        return np.zeros((frame_count, resolution, resolution, 3), dtype=np.float32)  # Return blank frames on error

!ls "/content/drive/MyDrive/ColabNotebooks/kin6-mini/train/crawling_baby/"

file_path = "/content/drive/MyDrive/ColabNotebooks/kin6-mini/train/crawling_baby/01Bp7-nCijA_000003_000013.mp4"
frame_count = 32
resolution = 224

clip = get_clip(file_path, frame_count, resolution)
print("Clip shape:", clip.shape)  # Expected output: (32, 224, 224, 3)

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Flatten # Import necessary layers
from tensorflow.keras.models import Model

def create_network(net1, input_img, class_count):
    """
    Creates a network using the provided base network (net1) and input tensor.

    Parameters:
        net1: The base network (e.g., Swin Transformer).
        input_img: The input tensor.
        class_count: The number of classes for classification.

    Returns:
        y: The output tensor of the network.
    """
    y0 = Lambda(lambda x: tf.transpose(x, perm=(0, 4, 1, 2, 3)))(input_img)
    y0 = net1(y0)
    y0 = Lambda(lambda x: tf.transpose(x, perm=(0, 2, 3, 4, 1)))(y0)
    y0 = tfa.layers.AdaptiveAveragePooling3D((1, 1, 1))(y0) # Assuming tfa is imported as tensorflow_addons
    y0 = Flatten()(y0)
    y0 = Dense(512, activation='relu')(y0)
    y0 = Dropout(0.3)(y0)
    y = Dense(class_count, activation='softmax')(y0)
    return y

# Load training and validation data
train_path = '/content/drive/MyDrive/ColabNotebooks/kin6-mini/train/*'
val_path = '/content/drive/MyDrive/ColabNotebooks/kin6-mini/test/*'

train_samples, train_labels = all_from_dir(train_path)
val_samples, val_labels = all_from_dir(val_path)

# Define the number of classes
class_count = np.max(train_labels) + 1

# Print dataset info for verification
print(f"Number of training samples: {len(train_samples)}")
print(f"Number of validation samples: {len(val_samples)}")
print(f"Number of classes: {class_count}")

!pip install tensorflow-addons

# Import necessary modules
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_addons as tfa  # Import tensorflow_addons
from tensorflow.keras.layers import Input, Lambda
from tensorflow.keras.models import Model

resolution = 224  # Reduced resolution
frame_count = 32 # Reduced frame count
batch_size = 1  # Reduced batch size

# Mixed precision training - Use 'mixed_float16' instead of 'mixed_float32'
from tensorflow.keras.mixed_precision import set_global_policy

# Set mixed precision policy to 'mixed_float16' for GPU acceleration
#set_global_policy('mixed_float16')
tf.keras.mixed_precision.set_global_policy('float32')


# Load Swin Transformer feature extractor
swin = hub.KerasLayer(
    "https://tfhub.dev/shoaib6174/swin_base_patch244_window877_kinetics600_22k/1",
    trainable=False,
)

# Define the create_network function
def create_network(net1, input_img, class_count):
    # Transpose to [batch, channels, time, height, width] for Swin input
    y0 = Lambda(lambda x: tf.transpose(x, perm=(0, 4, 1, 2, 3)))(input_img)
    y0 = net1(y0)  # Pass through Swin Transformer
    # Transpose back to [batch, time, height, width, channels]
    y0 = Lambda(lambda x: tf.transpose(x, perm=(0, 2, 3, 4, 1)))(y0)
    # Adaptive average pooling to reduce dimensions
    y0 = tfa.layers.AdaptiveAveragePooling3D((1, 1, 1))(y0)
    y0 = tf.keras.layers.Flatten()(y0)  # Flatten the pooled output
    y0 = tf.keras.layers.Dense(512, activation='relu')(y0)  # Fully connected layer
    y0 = tf.keras.layers.Dropout(0.3)(y0)  # Dropout for regularization
    y = tf.keras.layers.Dense(class_count, activation='softmax')(y0)  # Output layer
    return y

input_img = tf.keras.layers.Input(shape=(frame_count, resolution, resolution, 3))

y = create_network(swin, input_img, class_count)
model = tf.keras.Model(input_img, y)

# Compile the model
optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)
loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)  # Set from_logits=False
model.compile(optimizer=optimizer, loss=loss_fn, metrics=["accuracy"])

# Check model summary
model.summary()

import tensorflow as tf
from tensorflow.keras.utils import to_categorical

# Loss and optimizer
loss_fn = tf.keras.losses.CategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)

# Metrics to track accuracy
train_acc_metric = tf.keras.metrics.CategoricalAccuracy()
val_acc_metric = tf.keras.metrics.CategoricalAccuracy()

# Declare the training step as a separate @tf.function
@tf.function
def video_train_step(x_batch_train, y_batch_train):
    """
    A single training step to process a batch of video data.
    """
    with tf.GradientTape() as tape:
        logits = model(x_batch_train, training=True)  # Forward pass
        loss_value = loss_fn(y_batch_train, logits)  # Compute loss

    # Compute gradients and apply updates
    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))

    # Update training metric
    train_acc_metric.update_state(y_batch_train, logits)
    return loss_value

# Custom training loop
epochs = 4
batch_size = 2  # Reduced batch size
frame_count = 32
resolution = 224
n_class = class_count  # Replace with the number of classes in your dataset

for epoch in range(epochs):
    print(f"\nStart of epoch {epoch + 1}")

    # Process only a subset of the training data
    train_subset = list(zip(train_samples[:batch_size * 10], train_labels[:batch_size * 10]))
    train_generator = prepare_dataset(
        data=train_subset,
        batch_size=batch_size,
        frame_count=frame_count,
        resolution=resolution,
        n_class=n_class,
        shuffle=True,
    )

    # Training phase
    for step, (x_batch_train, y_batch_train) in enumerate(train_generator):
        loss_value = video_train_step(x_batch_train, y_batch_train)

        # Print loss every 100 steps
        if step % 100 == 0:
            print(f"Training loss (for one batch) at step {step}: {loss_value.numpy()}")

    # Display metrics at the end of an epoch
    train_acc = train_acc_metric.result()
    print(f"Training accuracy over epoch {epoch + 1}: {train_acc.numpy()}")
    train_acc_metric.reset_state()

    # Validation phase
    val_subset = list(zip(val_samples[:batch_size * 10], val_labels[:batch_size * 10]))
    val_generator = prepare_dataset(
        data=val_subset,
        batch_size=batch_size,
        frame_count=frame_count,
        resolution=resolution,
        n_class=n_class,
        shuffle=False,
    )

    for x_batch_val, y_batch_val in val_generator:
        val_logits = model(x_batch_val, training=False)
        val_acc_metric.update_state(y_batch_val, val_logits)

    val_acc = val_acc_metric.result()
    print(f"Validation accuracy over epoch {epoch + 1}: {val_acc.numpy()}")
    val_acc_metric.reset_state()

# Test phase
test_subset = list(zip(test_samples[:batch_size * 10], test_labels[:batch_size * 10]))
test_generator = prepare_dataset(
    data=test_subset,
    batch_size=batch_size,
    frame_count=frame_count,
    resolution=resolution,
    n_class=n_class,
    shuffle=False,
)

test_loss = 0
test_accuracy = 0
test_batches = 0
for x_batch_test, y_batch_test in test_generator:
    val_logits = model(x_batch_test, training=False)
    test_loss += loss_fn(y_batch_test, val_logits).numpy()
    test_accuracy += tf.keras.metrics.categorical_accuracy(y_batch_test, val_logits).numpy().mean()
    test_batches += 1

# Average the test loss and accuracy over all batches
test_loss /= test_batches
test_accuracy /= test_batches

print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")